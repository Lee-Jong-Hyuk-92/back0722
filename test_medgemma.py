import os
# from vertexai.preview.generative_models import GenerativeModel, Part # ì´ì œ ì´ ë¶€ë¶„ì€ í•„ìš” ì—†ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
import vertexai # vertexai.init()ì„ ìœ„í•´ ìœ ì§€
from google.cloud import aiplatform # â­ ì´ ì¤„ì„ ì¶”ê°€í•©ë‹ˆë‹¤. aiplatform ëª¨ë“ˆì„ ì§ì ‘ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from PIL import Image
import io
from google.cloud import storage # Google Cloud Storage í´ë¼ì´ì–¸íŠ¸
import json # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ ìœ ì§€
# from google.cloud.aiplatform_v1beta1.types import Endpoint # íƒ€ì… íŒíŠ¸ìš©ì´ë¯€ë¡œ ì œê±°í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.

# âœ… í™˜ê²½ë³€ìˆ˜ë¡œ GCP ì¸ì¦ í‚¤ ë“±ë¡
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = r"C:\Users\302-1\Desktop\backend0709-1\meditooth-7ce9efd0794b.json"

# âœ… GCP í”„ë¡œì íŠ¸ ì„¤ì •
PROJECT_ID = "meditooth"
LOCATION = "us-central1" # MedGemma ì—”ë“œí¬ì¸íŠ¸ê°€ ë°°í¬ëœ ë¦¬ì „

# âœ… Vertex AI ì´ˆê¸°í™”
vertexai.init(project=PROJECT_ID, location=LOCATION)

# --- ìƒˆë¡œìš´ MedGemma ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° ë°©ì‹ ---
# â­ 1. MedGemma ëª¨ë¸ì´ ë°°í¬ëœ ì—”ë“œí¬ì¸íŠ¸ IDë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
# ì‚¬ìš©ìë‹˜ì´ ì œê³µí•œ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ í™•ì¸ëœ ì—”ë“œí¬ì¸íŠ¸ IDì…ë‹ˆë‹¤.
MEDGEMMA_ENDPOINT_ID = "7198930337072676864"  # â† âœ… ì´ê²Œ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ID

# ì—”ë“œí¬ì¸íŠ¸ ê°ì²´ ë¡œë“œ (Vertex AI SDK)
# aiplatform.Endpointë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ google-cloud-aiplatform íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.
# pip install google-cloud-aiplatform
try:
    medgemma_endpoint = aiplatform.Endpoint( # â­ vertexai.Endpoint ëŒ€ì‹  aiplatform.Endpoint ì‚¬ìš©
        endpoint_name=MEDGEMMA_ENDPOINT_ID,
        project=PROJECT_ID,
        location=LOCATION,
    )
    print(f"Successfully connected to MedGemma Endpoint: {medgemma_endpoint.display_name}")
except Exception as e:
    print(f"Error connecting to MedGemma Endpoint: {e}")
    print("Please ensure you have deployed MedGemma to an endpoint in Vertex AI "
          "and replaced 'YOUR_MEDGEMMA_ENDPOINT_ID_HERE' with your actual endpoint ID.")
    exit() # ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° ì‹¤íŒ¨ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ

# âœ… ì´ë¯¸ì§€ íŒŒì¼ì„ GCSì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def upload_blob(bucket_name, source_file_name, destination_blob_name):
    """GCSì— íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  HTTP URL ë°˜í™˜"""
    storage_client = storage.Client(project=PROJECT_ID)
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)

    # ì´ë¯¸ì§€ë¥¼ 896x896 JPEGë¡œ ë¦¬ì‚¬ì´ì§• ë° ì¸ì½”ë”©
    with Image.open(source_file_name) as img:
        img = img.resize((896, 896), Image.BICUBIC)
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format='JPEG')
        image_bytes = img_byte_arr.getvalue()

    blob.upload_from_string(image_bytes, content_type='image/jpeg')

    # â­ blobì„ ê³µê°œë¡œ ì„¤ì • (í•„ìˆ˜)
    blob.make_public()

    # âœ… HTTP URL ë°˜í™˜
    return blob.public_url

# GCS ë²„í‚· ì´ë¦„ (ì§ì ‘ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ ë²„í‚· ì‚¬ìš©)
# â­ ì¤‘ìš”í•œ: ì´ ë²„í‚·ì€ MedGemma ëª¨ë¸ê³¼ ë™ì¼í•œ ë¦¬ì „ (us-central1)ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤!
GCS_BUCKET_NAME = "meditooth-medgemma-images-temp" # ì´ì „ì— ì‚¬ìš©í•œ ì´ë¦„ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
GCS_IMAGE_DESTINATION_PATH = "oral_image_896x896.jpeg" # GCSì— ì €ì¥ë  íŒŒì¼ ì´ë¦„

# ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ (ì‚¬ìš©ìë‹˜ì´ ì œê³µí•œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ)
local_image_path = r"C:\Users\302-1\Desktop\backend0709-1\images\original\121212_20250721160844223601_web_image.png"

# ì´ë¯¸ì§€ë¥¼ GCSì— ì—…ë¡œë“œí•˜ê³  URL ê°€ì ¸ì˜¤ê¸°
print(f"Uploading image to GCS bucket: {GCS_BUCKET_NAME}/{GCS_IMAGE_DESTINATION_PATH}")
try:
    gcs_image_url = upload_blob(GCS_BUCKET_NAME, local_image_path, GCS_IMAGE_DESTINATION_PATH)
    print(f"Image uploaded to: {gcs_image_url}")
except Exception as e:
    print(f"Error uploading image to GCS. Please ensure the bucket '{GCS_BUCKET_NAME}' exists in '{LOCATION}' region "
          f"and your service account has 'Storage Object Creator' role: {e}")
    exit()

# âœ… í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ ì •ì˜ (ë…¸íŠ¸ë¶ì—ì„œ ë³¸ `messages` í˜•ì‹ ì‚¬ìš©)
user_prompt = "ì´ í™˜ìì˜ êµ¬ê°• ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ ì¶©ì¹˜ì™€ ì‡ëª¸ ì§ˆí™˜ ê°€ëŠ¥ì„±ì„ ì„¤ëª…í•´ì¤˜. ë‹¤ë¥¸ AI ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ë•Œ ì‡ëª¸ì—¼ì¦ ì´ˆê¸°, ì¹˜ì„ë‹¨ê³„2 ë¼ê³  ë‚˜ì™”ì–´"
system_instruction = "ë‹¹ì‹ ì€ êµ¬ê°• ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ ì˜ì‚¬ì…ë‹ˆë‹¤. ë§¤ìš° ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."

messages = [
    {
        "role": "system",
        "content": [{"type": "text", "text": system_instruction}]
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": user_prompt},
            {"type": "image_url", "image_url": {"url": gcs_image_url}}
        ]
    }
]

# ì˜ˆì¸¡ ìš”ì²­ì„ ìœ„í•œ `instances` êµ¬ì¡°
instances = [
    {
        "@requestFormat": "chatCompletions",
        "messages": messages,
        "max_tokens": 1500, # ì‘ë‹µ ê¸¸ì´ë¥¼ ì ì ˆíˆ ì„¤ì • (ë…¸íŠ¸ë¶ì—ì„œ 500 ë˜ëŠ” 1500 ì‚¬ìš©)
        "temperature": 0.4 # í˜„ì¬ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€
    },
]

# âœ… MedGemma ìš”ì²­ (ì—”ë“œí¬ì¸íŠ¸ ê°ì²´ ì‚¬ìš©)
print("\nGenerating content from MedGemma Endpoint...")
try:
    result = medgemma_endpoint.predict(instances=instances)

    # âœ… ì‘ë‹µ íŒŒì‹±
    response = result.predictions["choices"][0]["message"]["content"]

    print("ğŸ¦· ë¶„ì„ ê²°ê³¼:")
    print(response)

except Exception as e:
    print(f"Error during prediction: {e}")
    print("Please check your MedGemma endpoint status and permissions.")